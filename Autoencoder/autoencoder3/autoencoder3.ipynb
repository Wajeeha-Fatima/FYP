{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-04-27 23:24:32.793576: I tensorflow/tsl/cuda/cudart_stub.cc:28] Could not find cuda drivers on your machine, GPU will not be used.\n",
      "2023-04-27 23:24:32.875532: I tensorflow/tsl/cuda/cudart_stub.cc:28] Could not find cuda drivers on your machine, GPU will not be used.\n",
      "2023-04-27 23:24:32.877242: I tensorflow/core/platform/cpu_feature_guard.cc:182] This TensorFlow binary is optimized to use available CPU instructions in performance-critical operations.\n",
      "To enable the following instructions: AVX2 FMA, in other operations, rebuild TensorFlow with the appropriate compiler flags.\n",
      "2023-04-27 23:24:34.605345: W tensorflow/compiler/tf2tensorrt/utils/py_utils.cc:38] TF-TRT Warning: Could not find TensorRT\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Shape of all sensors after up/down sample...  (4572, 400, 3) (4572, 400, 3) (4572, 400, 3) (4572, 400, 3) (4572, 400, 3) (4572, 400, 3) (4572, 400, 3) (4572, 400, 3) (4572, 400, 3)\n"
     ]
    }
   ],
   "source": [
    "# Average 60+% accuracy\n",
    "\n",
    "# -*- coding: utf-8 -*-\n",
    "\"\"\"CNN.ipynb\n",
    "\n",
    "Automatically generated by Colaboratory.\n",
    "\n",
    "Original file is located at\n",
    "    https://colab.research.google.com/drive/1RDQrJejOfArNgzjcXMDQ0C4bBzMljDtA\n",
    "\n",
    "# Connect with Google Drive\n",
    "\"\"\"\n",
    "\n",
    "# from google.colab import drive\n",
    "# drive.mount('/content/drive')\n",
    "\n",
    "\"\"\"# Importing Libraries\"\"\"\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "# import matplotlib.pyplot as plt\n",
    "import scipy\n",
    "from scipy.interpolate import interp1d\n",
    "from scipy.stats import kurtosis\n",
    "from scipy.stats import skew\n",
    "from sklearn import preprocessing\n",
    "from sklearn.preprocessing import normalize\n",
    "from scipy.ndimage import zoom\n",
    "from skimage.measure import block_reduce\n",
    "from skimage.transform import resize\n",
    "from sklearn.model_selection import train_test_split\n",
    "import tensorflow as tf\n",
    "from keras.optimizers import Adam\n",
    "from sklearn.metrics import f1_score, accuracy_score, confusion_matrix\n",
    "from tensorflow.keras.optimizers import Adam\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import BatchNormalization, Conv2D, MaxPooling2D, Flatten, Dense\n",
    "from tensorflow.keras.utils import to_categorical\n",
    "\n",
    "\"\"\"# Loading Data\"\"\"\n",
    "\n",
    "path = \"../../Cog_DataSets/testing/\"\n",
    "# path = \"drive/MyDrive/Colab Notebooks/CogAge/Datasets/testing/\"\n",
    "test_acc = np.load(path+\"testAccelerometer.npy\")\n",
    "test_grav = np.load(path+\"testGravity.npy\")\n",
    "test_gyro = np.load(path+\"testGyroscope.npy\")\n",
    "test_jinsAcc = np.load(path+\"testJinsAccelerometer.npy\")\n",
    "test_jinsGyro = np.load(path+\"testJinsGyroscope.npy\")\n",
    "test_Label =np.load(path+\"testLabels.npy\") \n",
    "test_linAcc = np.load(path+\"testLinearAcceleration.npy\")\n",
    "test_MsAcc = np.load(path+\"testMSAccelerometer.npy\")\n",
    "test_MsGyro = np.load(path + \"testMSGyroscope.npy\")\n",
    "test_MsMag = np.load(path+\"testMagnetometer.npy\")\n",
    "# test_acc\n",
    "\n",
    "path = \"../../Cog_DataSets/training/\"\n",
    "# path = \"drive/MyDrive/Colab Notebooks/CogAge/Datasets/training/\"\n",
    "train_acc = np.load(path+\"trainAccelerometer.npy\")\n",
    "train_grav = np.load(path+\"trainGravity.npy\")\n",
    "train_gyro = np.load(path+\"trainGyroscope.npy\")\n",
    "train_jinsAcc = np.load(path+\"trainJinsAccelerometer.npy\")\n",
    "train_jinsGyro = np.load(path+\"trainJinsGyroscope.npy\")\n",
    "train_Label =np.load(path+\"trainLabels.npy\") \n",
    "train_linAcc = np.load(path+\"trainLinearAcceleration.npy\")\n",
    "train_MsAcc = np.load(path+\"trainMSAccelerometer.npy\")\n",
    "train_MsGyro = np.load(path + \"trainMSGyroscope.npy\")\n",
    "train_MsMag = np.load(path+\"trainMagnetometer.npy\")\n",
    "# print(train_Label.shape)\n",
    "\n",
    "\n",
    "def Normalize(X):\n",
    "  norm = []\n",
    "  for I in range(len(X)):\n",
    "    norm.append(normalize(X[I]))\n",
    "  norm=np.array(norm)\n",
    "  return norm\n",
    "\n",
    "train_acc = Normalize(train_acc)\n",
    "train_gyro = Normalize(train_gyro)\n",
    "train_grav = Normalize(train_grav)\n",
    "train_linAcc = Normalize(train_linAcc)\n",
    "train_MsMag = Normalize(train_MsMag)\n",
    "train_MsAcc = Normalize(train_MsAcc)\n",
    "train_MsGyro = Normalize(train_MsGyro)\n",
    "train_jinsAcc = Normalize(train_jinsAcc)\n",
    "train_jinsGyro = Normalize(train_jinsGyro)\n",
    "\n",
    "test_acc = Normalize(test_acc)\n",
    "test_gyro = Normalize(test_gyro)\n",
    "test_grav = Normalize(test_grav)\n",
    "test_linAcc = Normalize(test_linAcc)\n",
    "test_MsMag = Normalize(test_MsMag)\n",
    "test_MsAcc = Normalize(test_MsAcc)\n",
    "test_MsGyro = Normalize(test_MsGyro)\n",
    "test_jinsAcc = Normalize(test_jinsAcc)\n",
    "test_jinsGyro = Normalize(test_jinsGyro)\n",
    "\n",
    "\n",
    "\n",
    "\"\"\"# Reshape and stack Data Before Fitting to Model\"\"\"\n",
    "# changing shape of sensor data to (#,400,3)\n",
    "# downsample\n",
    "train_acc_reshaped = block_reduce(train_acc, block_size=(1, 2, 1), func=np.mean)\n",
    "train_gyro_reshaped = block_reduce(train_gyro, block_size=(1, 2, 1), func=np.mean)\n",
    "train_grav_reshaped = block_reduce(train_grav, block_size=(1, 2, 1), func=np.mean)\n",
    "train_linAcc_reshaped = block_reduce(train_linAcc, block_size=(1, 2, 1), func=np.mean)\n",
    "# upsample\n",
    "train_MsAcc_reshaped = resize(train_MsAcc, (2284, 400, 3), mode='edge')\n",
    "train_MsGyro_reshaped = resize(train_MsGyro, (2284, 400, 3), mode='edge')\n",
    "# upsample\n",
    "train_MsMag_reshaped = np.repeat(train_MsMag, 2, axis=1)\n",
    "train_jinsAcc_reshaped = np.repeat(train_jinsAcc, 5, axis=1)\n",
    "train_jinsGyro_reshaped = np.repeat(train_jinsGyro, 5, axis=1)\n",
    "\n",
    "test_acc_reshaped = block_reduce(test_acc, block_size=(1, 2, 1), func=np.mean)\n",
    "test_gyro_reshaped = block_reduce(test_gyro, block_size=(1, 2, 1), func=np.mean)\n",
    "test_grav_reshaped = block_reduce(test_grav, block_size=(1, 2, 1), func=np.mean)\n",
    "test_linAcc_reshaped = block_reduce(test_linAcc, block_size=(1, 2, 1), func=np.mean)\n",
    "test_MsAcc_reshaped = resize(test_MsAcc, (2288, 400, 3), mode='edge')\n",
    "test_MsGyro_reshaped = resize(test_MsGyro, (2288, 400, 3), mode='edge')\n",
    "test_MsMag_reshaped = np.repeat(test_MsMag, 2, axis=1)\n",
    "test_jinsAcc_reshaped = np.repeat(test_jinsAcc, 5, axis=1)\n",
    "test_jinsGyro_reshaped = np.repeat(test_jinsGyro, 5, axis=1)\n",
    "\n",
    "# all data of shape #,400,3\n",
    "# adding all relative data.\n",
    "# Mobile training accelerometer + Mobile testing accelerometer data\n",
    "train_acc_reshaped = np.append(train_acc_reshaped,test_acc_reshaped, axis=0)\n",
    "train_gyro_reshaped = np.append(train_gyro_reshaped,test_gyro_reshaped, axis=0)\n",
    "train_grav_reshaped = np.append(train_grav_reshaped,test_grav_reshaped, axis=0)\n",
    "train_linAcc_reshaped = np.append(train_linAcc_reshaped,test_linAcc_reshaped, axis=0)\n",
    "train_MsAcc_reshaped = np.append(train_MsAcc_reshaped,test_MsAcc_reshaped, axis=0)\n",
    "train_MsGyro_reshaped = np.append(train_MsGyro_reshaped,test_MsGyro_reshaped, axis=0)\n",
    "train_MsMag_reshaped = np.append(train_MsMag_reshaped,test_MsMag_reshaped, axis=0)\n",
    "train_jinsAcc_reshaped = np.append(train_jinsAcc_reshaped,test_jinsAcc_reshaped, axis=0)\n",
    "train_jinsGyro_reshaped = np.append(train_jinsGyro_reshaped,test_jinsGyro_reshaped, axis=0)\n",
    "\n",
    "\n",
    "print(\"Shape of all sensors after up/down sample... \", train_acc_reshaped.shape, train_gyro_reshaped.shape, train_grav_reshaped.shape, train_linAcc_reshaped.shape\n",
    "                       , train_MsAcc_reshaped.shape, train_MsGyro_reshaped.shape, train_MsMag_reshaped.shape,\n",
    "                       train_jinsAcc_reshaped.shape, train_jinsGyro_reshaped.shape)\n",
    "\n",
    "# all data of shape 4572,400,3\n",
    "# 4572 = 2284(training) + 2288(testing)\n",
    "\n",
    "\n",
    "# stack\n",
    "all_data = np.stack([train_acc_reshaped, train_gyro_reshaped, train_grav_reshaped, train_linAcc_reshaped\n",
    "                       , train_MsAcc_reshaped, train_MsGyro_reshaped, train_MsMag_reshaped,\n",
    "                       train_jinsAcc_reshaped, train_jinsGyro_reshaped], axis=-1)\n",
    "\n",
    "all_Label = np.append(train_Label, test_Label, axis=-1)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Shape of training + validation Data\n",
      "(3657, 400, 3, 9) (915, 400, 3, 9)\n",
      "Shape of training + validation Labels\n",
      "(3657,) (915,)\n",
      "reshape:  (3657, 10800)\n",
      "reshape:  (915, 10800)\n"
     ]
    }
   ],
   "source": [
    "\n",
    "# # 90% training data + labels\n",
    "# train_data = all_data[: int(all_data.shape[0]*0.9)]\n",
    "# # 10% testing data + labels\n",
    "# test_data = all_data[int(all_data.shape[0]*0.9):]\n",
    "# train_labels = all_Label[: int(all_Label.shape[0]*0.9)]\n",
    "# test_labels = all_Label[int(all_Label.shape[0]*0.9):]\n",
    "\n",
    "# print(\"\\nShape of training and testin data + labels...\\n\")\n",
    "# print(train_data.shape, test_data.shape)\n",
    "# print(train_labels.shape, test_labels.shape)\n",
    "\n",
    "\n",
    "# Split the data into training and validation sets\n",
    "x_train, x_val, y_train, y_val = train_test_split(all_data, all_Label, test_size=0.2, random_state=42)\n",
    "\n",
    "print(\"Shape of training + validation Data\")\n",
    "print(np.shape(x_train), np.shape(x_val))\n",
    "\n",
    "# y_train = to_categorical(y_train, num_classes=55)\n",
    "# y_val = to_categorical(y_val, num_classes=55)\n",
    "\n",
    "print(\"Shape of training + validation Labels\")\n",
    "print(np.shape(y_train), np.shape(y_val))\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "# Reshape the input data to (3291, 400*3*9)\n",
    "# x_train = np.reshape(x_train, (x_train.shape[0], -1))\n",
    "train_data = np.reshape(x_train, (x_train.shape[0],-1))\n",
    "test_data = np.reshape(x_val, (x_val.shape[0],-1))\n",
    "input_shape=(400*3*9,)\n",
    "\n",
    "print(\"reshape: \", train_data.shape)\n",
    "print(\"reshape: \", test_data.shape)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Encoder dense 1 shape: ------------------------------\n",
      "(None, 2500)\n",
      "Encoder dense 2 shape: ------------------------------\n",
      "(None, 2500)\n",
      "Encoder dense 3 shape: ------------------------------\n",
      "(None, 2500)\n",
      "Decoder dense 1 shape: ------------------------------\n",
      "(None, 2500)\n",
      "Decoder dense 2 shape: ------------------------------\n",
      "(None, 2500)\n",
      "Decoder dense 3 shape: ------------------------------\n",
      "(None, 2500)\n",
      "Output shape: ------------------------------\n",
      "(None, 10800)\n"
     ]
    }
   ],
   "source": [
    "# HYPER PARAMTERS\n",
    "\n",
    "# Filter parameters, i.e. about the number of inputs processed by each neuron of the convolutional layer\n",
    "filter1Size = (11,1)\n",
    "filter2Size = (13,1)\n",
    "filter3Size = (13,1)\n",
    "\n",
    "# Downsampling factors of the pooling layers\n",
    "poolingLayer1Factor = (2,1)\n",
    "poolingLayer2Factor = (3,1)\n",
    "poolingLayer3Factor = (2,1)\n",
    "\n",
    "# Number of feature maps processed by each convolutional layer\n",
    "nbFeaturesLayer1 = 50\n",
    "nbFeaturesLayer2 = 40\n",
    "nbFeaturesLayer3 = 30\n",
    "\n",
    "# Activation function of the convolutional layer(s)\n",
    "activationConv = 'relu'\n",
    "\n",
    "# Output dimension of the LSTM\n",
    "outputLSTM = 100\n",
    "\n",
    "# Parameters of the dense layer\n",
    "activationMLP = 'relu'\n",
    "inputMLP = 2500\n",
    "\n",
    "# Training parameters\n",
    "batchSize = 200\n",
    "numberOfEpochs = 10\n",
    "learningRate = 0.001\n",
    "\n",
    "# input_shape = (400,3,9)\n",
    "nbClasses = 55\n",
    "\n",
    "#-------------------------------------------------------------------------------------------------------\n",
    "# autoencoder3: define a autoencoder with 3 hidden layers\n",
    "#-------------------------------------------------------------------------------------------------------\n",
    "def autoencoder3(\n",
    "    inputShape,\n",
    "    inputMLP1,\n",
    "    inputMLP2,\n",
    "    inputMLP3,\n",
    "    activationMLP,\n",
    "    decoder=True):\n",
    "\n",
    "    model = Sequential()\n",
    "\n",
    "    model.add(BatchNormalization(input_shape=inputShape))\n",
    "\n",
    "    # Dense layer 1 of the encoder\n",
    "    model.add(Dense(inputMLP1,activation=activationMLP))\n",
    "    print('Encoder dense 1 shape: ------------------------------')\n",
    "    print(model.layers[-1].output_shape)\n",
    "\n",
    "    # Dense layer 2 of the encoder\n",
    "    model.add(Dense(inputMLP2,activation=activationMLP))\n",
    "    print('Encoder dense 2 shape: ------------------------------')\n",
    "    print(model.layers[-1].output_shape)\n",
    "\n",
    "    # Dense layer 3 of the encoder\n",
    "    model.add(Dense(inputMLP3,activation=activationMLP))\n",
    "    print('Encoder dense 3 shape: ------------------------------')\n",
    "    print(model.layers[-1].output_shape)\n",
    "\n",
    "\n",
    "    if decoder:\n",
    "\n",
    "        # Dense layer 1 of the decoder\n",
    "        model.add(Dense(inputMLP3,activation=activationMLP))\n",
    "        print('Decoder dense 1 shape: ------------------------------')\n",
    "        print(model.layers[-1].output_shape)\n",
    "\n",
    "        # Dense layer 1 of the decoder\n",
    "        model.add(Dense(inputMLP2,activation=activationMLP))\n",
    "        print('Decoder dense 2 shape: ------------------------------')\n",
    "        print(model.layers[-1].output_shape)\n",
    "\n",
    "        # Dense layer 2 of the decoder\n",
    "        model.add(Dense(inputMLP1,activation=activationMLP))\n",
    "        print('Decoder dense 3 shape: ------------------------------')\n",
    "        print(model.layers[-1].output_shape)\n",
    "\n",
    "        # Batch normalization\n",
    "        model.add(BatchNormalization())\n",
    "\n",
    "        # Output layer\n",
    "        model.add(Dense(inputShape[0],activation='linear')) \n",
    "        print('Output shape: ------------------------------')\n",
    "        print(model.layers[-1].output_shape)      \n",
    "\n",
    "    return model\n",
    "\n",
    "model = autoencoder3(\n",
    "              inputShape=input_shape,\n",
    "              inputMLP1=inputMLP,\n",
    "              inputMLP2=inputMLP,\n",
    "              inputMLP3=inputMLP,\n",
    "              activationMLP=activationMLP)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'model' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[1], line 1\u001b[0m\n\u001b[0;32m----> 1\u001b[0m model\u001b[39m.\u001b[39mcompile(\n\u001b[1;32m      2\u001b[0m     loss\u001b[39m=\u001b[39m\u001b[39m'\u001b[39m\u001b[39mmse\u001b[39m\u001b[39m'\u001b[39m,\n\u001b[1;32m      3\u001b[0m     optimizer\u001b[39m=\u001b[39mAdam(learning_rate\u001b[39m=\u001b[39mlearningRate),\n\u001b[1;32m      4\u001b[0m     metrics\u001b[39m=\u001b[39m[\u001b[39m'\u001b[39m\u001b[39maccuracy\u001b[39m\u001b[39m'\u001b[39m]\n\u001b[1;32m      5\u001b[0m )\n\u001b[1;32m      8\u001b[0m model\u001b[39m.\u001b[39mfit(x\u001b[39m=\u001b[39mtrain_data, y\u001b[39m=\u001b[39mtrain_data, epochs\u001b[39m=\u001b[39m\u001b[39m8\u001b[39m, batch_size\u001b[39m=\u001b[39mbatchSize, validation_data\u001b[39m=\u001b[39m(test_data, test_data))\n",
      "\u001b[0;31mNameError\u001b[0m: name 'model' is not defined"
     ]
    }
   ],
   "source": [
    "model.compile(\n",
    "    loss='mse',\n",
    "    optimizer=Adam(learning_rate=learningRate),\n",
    "    metrics=['accuracy']\n",
    ")\n",
    "\n",
    "\n",
    "model.fit(x=train_data, y=train_data, epochs=8, batch_size=batchSize, validation_data=(test_data, test_data))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " batch_normalization (BatchN  (None, 10800)            43200     \n",
      " ormalization)                                                   \n",
      "                                                                 \n",
      " dense (Dense)               (None, 2500)              27002500  \n",
      "                                                                 \n",
      " dense_1 (Dense)             (None, 2500)              6252500   \n",
      "                                                                 \n",
      " dense_2 (Dense)             (None, 2500)              6252500   \n",
      "                                                                 \n",
      " dense_3 (Dense)             (None, 2500)              6252500   \n",
      "                                                                 \n",
      " dense_4 (Dense)             (None, 2500)              6252500   \n",
      "                                                                 \n",
      " dense_5 (Dense)             (None, 2500)              6252500   \n",
      "                                                                 \n",
      " batch_normalization_1 (Batc  (None, 2500)             10000     \n",
      " hNormalization)                                                 \n",
      "                                                                 \n",
      " dense_6 (Dense)             (None, 10800)             27010800  \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 85,329,000\n",
      "Trainable params: 85,302,400\n",
      "Non-trainable params: 26,600\n",
      "_________________________________________________________________\n",
      "115/115 [==============================] - 13s 113ms/step\n",
      "29/29 [==============================] - 3s 105ms/step\n"
     ]
    }
   ],
   "source": [
    "model.summary()\n",
    "\n",
    "from sklearn.svm import SVC\n",
    "\n",
    "x_train_compressed = model.predict(train_data)\n",
    "x_test_compressed = model.predict(test_data)\n",
    "\n",
    "# Train an SVM classifier on the compressed data\n",
    "svm = SVC(kernel='linear')\n",
    "svm.fit(x_train_compressed, y_train)\n",
    "\n",
    "# print(x_train_comp.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Evaluate the accuracy of the SVM classifier\n",
    "svm_score = svm.score(x_test_compressed, y_val)\n",
    "print(\"Accuracy: %.2f%%\" % (svm_score*100))\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.6"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
