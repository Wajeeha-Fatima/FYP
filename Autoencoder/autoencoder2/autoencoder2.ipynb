{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-04-27 23:19:13.567024: I tensorflow/tsl/cuda/cudart_stub.cc:28] Could not find cuda drivers on your machine, GPU will not be used.\n",
      "2023-04-27 23:19:13.623481: I tensorflow/tsl/cuda/cudart_stub.cc:28] Could not find cuda drivers on your machine, GPU will not be used.\n",
      "2023-04-27 23:19:13.624448: I tensorflow/core/platform/cpu_feature_guard.cc:182] This TensorFlow binary is optimized to use available CPU instructions in performance-critical operations.\n",
      "To enable the following instructions: AVX2 FMA, in other operations, rebuild TensorFlow with the appropriate compiler flags.\n",
      "2023-04-27 23:19:14.458516: W tensorflow/compiler/tf2tensorrt/utils/py_utils.cc:38] TF-TRT Warning: Could not find TensorRT\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Shape of all sensors after up/down sample...  (4572, 400, 3) (4572, 400, 3) (4572, 400, 3) (4572, 400, 3) (4572, 400, 3) (4572, 400, 3) (4572, 400, 3) (4572, 400, 3) (4572, 400, 3)\n"
     ]
    }
   ],
   "source": [
    "# Average 60+% accuracy\n",
    "\n",
    "# -*- coding: utf-8 -*-\n",
    "\"\"\"CNN.ipynb\n",
    "\n",
    "Automatically generated by Colaboratory.\n",
    "\n",
    "Original file is located at\n",
    "    https://colab.research.google.com/drive/1RDQrJejOfArNgzjcXMDQ0C4bBzMljDtA\n",
    "\n",
    "# Connect with Google Drive\n",
    "\"\"\"\n",
    "\n",
    "# from google.colab import drive\n",
    "# drive.mount('/content/drive')\n",
    "\n",
    "\"\"\"# Importing Libraries\"\"\"\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "# import matplotlib.pyplot as plt\n",
    "import scipy\n",
    "from scipy.interpolate import interp1d\n",
    "from scipy.stats import kurtosis\n",
    "from scipy.stats import skew\n",
    "from sklearn import preprocessing\n",
    "from sklearn.preprocessing import normalize\n",
    "from scipy.ndimage import zoom\n",
    "from skimage.measure import block_reduce\n",
    "from skimage.transform import resize\n",
    "from sklearn.model_selection import train_test_split\n",
    "import tensorflow as tf\n",
    "from keras.optimizers import Adam\n",
    "from sklearn.metrics import f1_score, accuracy_score, confusion_matrix\n",
    "from tensorflow.keras.optimizers import Adam\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import BatchNormalization, Conv2D, MaxPooling2D, Flatten, Dense\n",
    "from tensorflow.keras.utils import to_categorical\n",
    "\n",
    "\"\"\"# Loading Data\"\"\"\n",
    "\n",
    "path = \"../../Cog_DataSets/testing/\"\n",
    "# path = \"drive/MyDrive/Colab Notebooks/CogAge/Datasets/testing/\"\n",
    "test_acc = np.load(path+\"testAccelerometer.npy\")\n",
    "test_grav = np.load(path+\"testGravity.npy\")\n",
    "test_gyro = np.load(path+\"testGyroscope.npy\")\n",
    "test_jinsAcc = np.load(path+\"testJinsAccelerometer.npy\")\n",
    "test_jinsGyro = np.load(path+\"testJinsGyroscope.npy\")\n",
    "test_Label =np.load(path+\"testLabels.npy\") \n",
    "test_linAcc = np.load(path+\"testLinearAcceleration.npy\")\n",
    "test_MsAcc = np.load(path+\"testMSAccelerometer.npy\")\n",
    "test_MsGyro = np.load(path + \"testMSGyroscope.npy\")\n",
    "test_MsMag = np.load(path+\"testMagnetometer.npy\")\n",
    "# test_acc\n",
    "\n",
    "path = \"../../Cog_DataSets/training/\"\n",
    "# path = \"drive/MyDrive/Colab Notebooks/CogAge/Datasets/training/\"\n",
    "train_acc = np.load(path+\"trainAccelerometer.npy\")\n",
    "train_grav = np.load(path+\"trainGravity.npy\")\n",
    "train_gyro = np.load(path+\"trainGyroscope.npy\")\n",
    "train_jinsAcc = np.load(path+\"trainJinsAccelerometer.npy\")\n",
    "train_jinsGyro = np.load(path+\"trainJinsGyroscope.npy\")\n",
    "train_Label =np.load(path+\"trainLabels.npy\") \n",
    "train_linAcc = np.load(path+\"trainLinearAcceleration.npy\")\n",
    "train_MsAcc = np.load(path+\"trainMSAccelerometer.npy\")\n",
    "train_MsGyro = np.load(path + \"trainMSGyroscope.npy\")\n",
    "train_MsMag = np.load(path+\"trainMagnetometer.npy\")\n",
    "# print(train_Label.shape)\n",
    "\n",
    "\n",
    "def Normalize(X):\n",
    "  norm = []\n",
    "  for I in range(len(X)):\n",
    "    norm.append(normalize(X[I]))\n",
    "  norm=np.array(norm)\n",
    "  return norm\n",
    "\n",
    "train_acc = Normalize(train_acc)\n",
    "train_gyro = Normalize(train_gyro)\n",
    "train_grav = Normalize(train_grav)\n",
    "train_linAcc = Normalize(train_linAcc)\n",
    "train_MsMag = Normalize(train_MsMag)\n",
    "train_MsAcc = Normalize(train_MsAcc)\n",
    "train_MsGyro = Normalize(train_MsGyro)\n",
    "train_jinsAcc = Normalize(train_jinsAcc)\n",
    "train_jinsGyro = Normalize(train_jinsGyro)\n",
    "\n",
    "test_acc = Normalize(test_acc)\n",
    "test_gyro = Normalize(test_gyro)\n",
    "test_grav = Normalize(test_grav)\n",
    "test_linAcc = Normalize(test_linAcc)\n",
    "test_MsMag = Normalize(test_MsMag)\n",
    "test_MsAcc = Normalize(test_MsAcc)\n",
    "test_MsGyro = Normalize(test_MsGyro)\n",
    "test_jinsAcc = Normalize(test_jinsAcc)\n",
    "test_jinsGyro = Normalize(test_jinsGyro)\n",
    "\n",
    "\n",
    "\n",
    "\"\"\"# Reshape and stack Data Before Fitting to Model\"\"\"\n",
    "# changing shape of sensor data to (#,400,3)\n",
    "# downsample\n",
    "train_acc_reshaped = block_reduce(train_acc, block_size=(1, 2, 1), func=np.mean)\n",
    "train_gyro_reshaped = block_reduce(train_gyro, block_size=(1, 2, 1), func=np.mean)\n",
    "train_grav_reshaped = block_reduce(train_grav, block_size=(1, 2, 1), func=np.mean)\n",
    "train_linAcc_reshaped = block_reduce(train_linAcc, block_size=(1, 2, 1), func=np.mean)\n",
    "# upsample\n",
    "train_MsAcc_reshaped = resize(train_MsAcc, (2284, 400, 3), mode='edge')\n",
    "train_MsGyro_reshaped = resize(train_MsGyro, (2284, 400, 3), mode='edge')\n",
    "# upsample\n",
    "train_MsMag_reshaped = np.repeat(train_MsMag, 2, axis=1)\n",
    "train_jinsAcc_reshaped = np.repeat(train_jinsAcc, 5, axis=1)\n",
    "train_jinsGyro_reshaped = np.repeat(train_jinsGyro, 5, axis=1)\n",
    "\n",
    "test_acc_reshaped = block_reduce(test_acc, block_size=(1, 2, 1), func=np.mean)\n",
    "test_gyro_reshaped = block_reduce(test_gyro, block_size=(1, 2, 1), func=np.mean)\n",
    "test_grav_reshaped = block_reduce(test_grav, block_size=(1, 2, 1), func=np.mean)\n",
    "test_linAcc_reshaped = block_reduce(test_linAcc, block_size=(1, 2, 1), func=np.mean)\n",
    "test_MsAcc_reshaped = resize(test_MsAcc, (2288, 400, 3), mode='edge')\n",
    "test_MsGyro_reshaped = resize(test_MsGyro, (2288, 400, 3), mode='edge')\n",
    "test_MsMag_reshaped = np.repeat(test_MsMag, 2, axis=1)\n",
    "test_jinsAcc_reshaped = np.repeat(test_jinsAcc, 5, axis=1)\n",
    "test_jinsGyro_reshaped = np.repeat(test_jinsGyro, 5, axis=1)\n",
    "\n",
    "# all data of shape #,400,3\n",
    "# adding all relative data.\n",
    "# Mobile training accelerometer + Mobile testing accelerometer data\n",
    "train_acc_reshaped = np.append(train_acc_reshaped,test_acc_reshaped, axis=0)\n",
    "train_gyro_reshaped = np.append(train_gyro_reshaped,test_gyro_reshaped, axis=0)\n",
    "train_grav_reshaped = np.append(train_grav_reshaped,test_grav_reshaped, axis=0)\n",
    "train_linAcc_reshaped = np.append(train_linAcc_reshaped,test_linAcc_reshaped, axis=0)\n",
    "train_MsAcc_reshaped = np.append(train_MsAcc_reshaped,test_MsAcc_reshaped, axis=0)\n",
    "train_MsGyro_reshaped = np.append(train_MsGyro_reshaped,test_MsGyro_reshaped, axis=0)\n",
    "train_MsMag_reshaped = np.append(train_MsMag_reshaped,test_MsMag_reshaped, axis=0)\n",
    "train_jinsAcc_reshaped = np.append(train_jinsAcc_reshaped,test_jinsAcc_reshaped, axis=0)\n",
    "train_jinsGyro_reshaped = np.append(train_jinsGyro_reshaped,test_jinsGyro_reshaped, axis=0)\n",
    "\n",
    "\n",
    "print(\"Shape of all sensors after up/down sample... \", train_acc_reshaped.shape, train_gyro_reshaped.shape, train_grav_reshaped.shape, train_linAcc_reshaped.shape\n",
    "                       , train_MsAcc_reshaped.shape, train_MsGyro_reshaped.shape, train_MsMag_reshaped.shape,\n",
    "                       train_jinsAcc_reshaped.shape, train_jinsGyro_reshaped.shape)\n",
    "\n",
    "# all data of shape 4572,400,3\n",
    "# 4572 = 2284(training) + 2288(testing)\n",
    "\n",
    "\n",
    "# stack\n",
    "all_data = np.stack([train_acc_reshaped, train_gyro_reshaped, train_grav_reshaped, train_linAcc_reshaped\n",
    "                       , train_MsAcc_reshaped, train_MsGyro_reshaped, train_MsMag_reshaped,\n",
    "                       train_jinsAcc_reshaped, train_jinsGyro_reshaped], axis=-1)\n",
    "\n",
    "all_Label = np.append(train_Label, test_Label, axis=-1)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Shape of training + validation Data\n",
      "(3657, 400, 3, 9) (915, 400, 3, 9)\n",
      "Shape of training + validation Labels\n",
      "(3657,) (915,)\n",
      "reshape:  (3657, 10800)\n",
      "reshape:  (915, 10800)\n"
     ]
    }
   ],
   "source": [
    "\n",
    "# # 90% training data + labels\n",
    "# train_data = all_data[: int(all_data.shape[0]*0.9)]\n",
    "# # 10% testing data + labels\n",
    "# test_data = all_data[int(all_data.shape[0]*0.9):]\n",
    "# train_labels = all_Label[: int(all_Label.shape[0]*0.9)]\n",
    "# test_labels = all_Label[int(all_Label.shape[0]*0.9):]\n",
    "\n",
    "# print(\"\\nShape of training and testin data + labels...\\n\")\n",
    "# print(train_data.shape, test_data.shape)\n",
    "# print(train_labels.shape, test_labels.shape)\n",
    "\n",
    "\n",
    "# Split the data into training and validation sets\n",
    "x_train, x_val, y_train, y_val = train_test_split(all_data, all_Label, test_size=0.2, random_state=42)\n",
    "\n",
    "print(\"Shape of training + validation Data\")\n",
    "print(np.shape(x_train), np.shape(x_val))\n",
    "\n",
    "# y_train = to_categorical(y_train, num_classes=55)\n",
    "# y_val = to_categorical(y_val, num_classes=55)\n",
    "\n",
    "print(\"Shape of training + validation Labels\")\n",
    "print(np.shape(y_train), np.shape(y_val))\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "# Reshape the input data to (3291, 400*3*9)\n",
    "# x_train = np.reshape(x_train, (x_train.shape[0], -1))\n",
    "train_data = np.reshape(x_train, (x_train.shape[0],-1))\n",
    "test_data = np.reshape(x_val, (x_val.shape[0],-1))\n",
    "input_shape=(400*3*9,)\n",
    "\n",
    "print(\"reshape: \", train_data.shape)\n",
    "print(\"reshape: \", test_data.shape)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Encoder dense 1 shape: ------------------------------\n",
      "(None, 2500)\n",
      "Encoder dense 2 shape: ------------------------------\n",
      "(None, 2500)\n",
      "Decoder dense 1 shape: ------------------------------\n",
      "(None, 2500)\n",
      "Decoder dense 2 shape: ------------------------------\n",
      "(None, 2500)\n",
      "Output shape: ------------------------------\n",
      "(None, 10800)\n"
     ]
    }
   ],
   "source": [
    "# HYPER PARAMTERS\n",
    "\n",
    "# Filter parameters, i.e. about the number of inputs processed by each neuron of the convolutional layer\n",
    "filter1Size = (11,1)\n",
    "filter2Size = (13,1)\n",
    "filter3Size = (13,1)\n",
    "\n",
    "# Downsampling factors of the pooling layers\n",
    "poolingLayer1Factor = (2,1)\n",
    "poolingLayer2Factor = (3,1)\n",
    "poolingLayer3Factor = (2,1)\n",
    "\n",
    "# Number of feature maps processed by each convolutional layer\n",
    "nbFeaturesLayer1 = 50\n",
    "nbFeaturesLayer2 = 40\n",
    "nbFeaturesLayer3 = 30\n",
    "\n",
    "# Activation function of the convolutional layer(s)\n",
    "activationConv = 'relu'\n",
    "\n",
    "# Output dimension of the LSTM\n",
    "outputLSTM = 100\n",
    "\n",
    "# Parameters of the dense layer\n",
    "activationMLP = 'relu'\n",
    "inputMLP = 2500\n",
    "\n",
    "# Training parameters\n",
    "batchSize = 200\n",
    "numberOfEpochs = 10\n",
    "learningRate = 0.001\n",
    "\n",
    "# input_shape = (400,3,9)\n",
    "nbClasses = 55\n",
    "\n",
    "#-------------------------------------------------------------------------------------------------------\n",
    "# autoencoder2: define a autoencoder with 2 hidden layers\n",
    "#-------------------------------------------------------------------------------------------------------\n",
    "def autoencoder2(\n",
    "    inputShape,\n",
    "    inputMLP1,\n",
    "    inputMLP2,\n",
    "    activationMLP,\n",
    "    decoder=True):\n",
    "\n",
    "    model = Sequential()\n",
    "\n",
    "    # Dense layer 1 of the encoder\n",
    "    model.add(Dense(inputMLP1,input_shape=inputShape,activation=activationMLP))\n",
    "    print('Encoder dense 1 shape: ------------------------------')\n",
    "    print(model.layers[-1].output_shape)\n",
    "\n",
    "    # Dense layer 2 of the encoder\n",
    "    model.add(Dense(inputMLP2,activation=activationMLP))\n",
    "    print('Encoder dense 2 shape: ------------------------------')\n",
    "    print(model.layers[-1].output_shape)\n",
    "\n",
    "\n",
    "    if decoder:\n",
    "\n",
    "        # Dense layer 1 of the decoder\n",
    "        model.add(Dense(inputMLP2,activation=activationMLP))\n",
    "        print('Decoder dense 1 shape: ------------------------------')\n",
    "        print(model.layers[-1].output_shape)\n",
    "\n",
    "        # Dense layer 2 of the decoder\n",
    "        model.add(Dense(inputMLP1,activation=activationMLP))\n",
    "        print('Decoder dense 2 shape: ------------------------------')\n",
    "        print(model.layers[-1].output_shape)\n",
    "\n",
    "        # Output layer\n",
    "        model.add(Dense(inputShape[0],activation='linear')) \n",
    "        print('Output shape: ------------------------------')\n",
    "        print(model.layers[-1].output_shape)      \n",
    "\n",
    "    return model\n",
    "\n",
    "model = autoencoder2(inputShape=input_shape,\n",
    "                          inputMLP1=inputMLP,\n",
    "                          inputMLP2=inputMLP,\n",
    "                          activationMLP=activationMLP)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/2\n",
      "19/19 [==============================] - 27s 1s/step - loss: 0.2210 - accuracy: 0.0014 - val_loss: 0.1642 - val_accuracy: 0.0011\n",
      "Epoch 2/2\n",
      "19/19 [==============================] - 28s 2s/step - loss: 0.1513 - accuracy: 8.2034e-04 - val_loss: 0.1407 - val_accuracy: 0.0011\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x7f0e4aa93ca0>"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.compile(\n",
    "    loss='mse',\n",
    "    optimizer=Adam(learning_rate=learningRate),\n",
    "    metrics=['accuracy']\n",
    ")\n",
    "\n",
    "\n",
    "model.fit(x=train_data, y=train_data, epochs=2, batch_size=batchSize, validation_data=(test_data, test_data))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " dense (Dense)               (None, 2500)              27002500  \n",
      "                                                                 \n",
      " dense_1 (Dense)             (None, 2500)              6252500   \n",
      "                                                                 \n",
      " dense_2 (Dense)             (None, 2500)              6252500   \n",
      "                                                                 \n",
      " dense_3 (Dense)             (None, 2500)              6252500   \n",
      "                                                                 \n",
      " dense_4 (Dense)             (None, 10800)             27010800  \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 72,770,800\n",
      "Trainable params: 72,770,800\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "115/115 [==============================] - 10s 89ms/step\n",
      "29/29 [==============================] - 3s 98ms/step\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<style>#sk-container-id-1 {color: black;background-color: white;}#sk-container-id-1 pre{padding: 0;}#sk-container-id-1 div.sk-toggleable {background-color: white;}#sk-container-id-1 label.sk-toggleable__label {cursor: pointer;display: block;width: 100%;margin-bottom: 0;padding: 0.3em;box-sizing: border-box;text-align: center;}#sk-container-id-1 label.sk-toggleable__label-arrow:before {content: \"▸\";float: left;margin-right: 0.25em;color: #696969;}#sk-container-id-1 label.sk-toggleable__label-arrow:hover:before {color: black;}#sk-container-id-1 div.sk-estimator:hover label.sk-toggleable__label-arrow:before {color: black;}#sk-container-id-1 div.sk-toggleable__content {max-height: 0;max-width: 0;overflow: hidden;text-align: left;background-color: #f0f8ff;}#sk-container-id-1 div.sk-toggleable__content pre {margin: 0.2em;color: black;border-radius: 0.25em;background-color: #f0f8ff;}#sk-container-id-1 input.sk-toggleable__control:checked~div.sk-toggleable__content {max-height: 200px;max-width: 100%;overflow: auto;}#sk-container-id-1 input.sk-toggleable__control:checked~label.sk-toggleable__label-arrow:before {content: \"▾\";}#sk-container-id-1 div.sk-estimator input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-1 div.sk-label input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-1 input.sk-hidden--visually {border: 0;clip: rect(1px 1px 1px 1px);clip: rect(1px, 1px, 1px, 1px);height: 1px;margin: -1px;overflow: hidden;padding: 0;position: absolute;width: 1px;}#sk-container-id-1 div.sk-estimator {font-family: monospace;background-color: #f0f8ff;border: 1px dotted black;border-radius: 0.25em;box-sizing: border-box;margin-bottom: 0.5em;}#sk-container-id-1 div.sk-estimator:hover {background-color: #d4ebff;}#sk-container-id-1 div.sk-parallel-item::after {content: \"\";width: 100%;border-bottom: 1px solid gray;flex-grow: 1;}#sk-container-id-1 div.sk-label:hover label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-1 div.sk-serial::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: 0;}#sk-container-id-1 div.sk-serial {display: flex;flex-direction: column;align-items: center;background-color: white;padding-right: 0.2em;padding-left: 0.2em;position: relative;}#sk-container-id-1 div.sk-item {position: relative;z-index: 1;}#sk-container-id-1 div.sk-parallel {display: flex;align-items: stretch;justify-content: center;background-color: white;position: relative;}#sk-container-id-1 div.sk-item::before, #sk-container-id-1 div.sk-parallel-item::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: -1;}#sk-container-id-1 div.sk-parallel-item {display: flex;flex-direction: column;z-index: 1;position: relative;background-color: white;}#sk-container-id-1 div.sk-parallel-item:first-child::after {align-self: flex-end;width: 50%;}#sk-container-id-1 div.sk-parallel-item:last-child::after {align-self: flex-start;width: 50%;}#sk-container-id-1 div.sk-parallel-item:only-child::after {width: 0;}#sk-container-id-1 div.sk-dashed-wrapped {border: 1px dashed gray;margin: 0 0.4em 0.5em 0.4em;box-sizing: border-box;padding-bottom: 0.4em;background-color: white;}#sk-container-id-1 div.sk-label label {font-family: monospace;font-weight: bold;display: inline-block;line-height: 1.2em;}#sk-container-id-1 div.sk-label-container {text-align: center;}#sk-container-id-1 div.sk-container {/* jupyter's `normalize.less` sets `[hidden] { display: none; }` but bootstrap.min.css set `[hidden] { display: none !important; }` so we also need the `!important` here to be able to override the default hidden behavior on the sphinx rendered scikit-learn.org. See: https://github.com/scikit-learn/scikit-learn/issues/21755 */display: inline-block !important;position: relative;}#sk-container-id-1 div.sk-text-repr-fallback {display: none;}</style><div id=\"sk-container-id-1\" class=\"sk-top-container\"><div class=\"sk-text-repr-fallback\"><pre>SVC(kernel=&#x27;linear&#x27;)</pre><b>In a Jupyter environment, please rerun this cell to show the HTML representation or trust the notebook. <br />On GitHub, the HTML representation is unable to render, please try loading this page with nbviewer.org.</b></div><div class=\"sk-container\" hidden><div class=\"sk-item\"><div class=\"sk-estimator sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-1\" type=\"checkbox\" checked><label for=\"sk-estimator-id-1\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">SVC</label><div class=\"sk-toggleable__content\"><pre>SVC(kernel=&#x27;linear&#x27;)</pre></div></div></div></div></div>"
      ],
      "text/plain": [
       "SVC(kernel='linear')"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.summary()\n",
    "\n",
    "from sklearn.svm import SVC\n",
    "\n",
    "x_train_compressed = model.predict(train_data)\n",
    "x_test_compressed = model.predict(test_data)\n",
    "\n",
    "# Train an SVM classifier on the compressed data\n",
    "svm = SVC(kernel='linear')\n",
    "svm.fit(x_train_compressed, y_train)\n",
    "\n",
    "# print(x_train_comp.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 54.21%\n"
     ]
    }
   ],
   "source": [
    "# Evaluate the accuracy of the SVM classifier\n",
    "svm_score = svm.score(x_test_compressed, y_val)\n",
    "print(\"Accuracy: %.2f%%\" % (svm_score*100))\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.6"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
